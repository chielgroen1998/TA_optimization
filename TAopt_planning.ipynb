{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AStTPO6wzdGj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# klein beginnen, dan uitbouwen, \n",
        "# eerst nasdaq, dan twelve, dan nasdaq 100, etc etc\n",
        "# eerst RSI, dan RSI en ... dan mischine boolean on or offs\n",
        "# gridsearch dan bayesian, en ik geloof stiekem dat GP's mischien makkelijker zijn hahahhaha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "TICKERS = [\n",
        "    # Nasdaq Top 20\n",
        "    \"NVDA\",\"MSFT\",\"AAPL\",\"GOOGL\",\"AMZN\",\"META\",\"TSLA\",\"AVGO\",\"TSM\",\"INTC\",\n",
        "    \"ADBE\",\"CMCSA\",\"CSCO\",\"PEP\",\"TXN\",\"PYPL\",\"QCOM\",\"AMGN\",\"GILD\",\"CHTR\",\n",
        "\n",
        "    # Europe Top 10\n",
        "    \"SAP\",\"ASML\",\"MC.PA\",\"RMS.PA\",\"OR.PA\",\"AZN\",\"VGK\",\n",
        "\n",
        "    # Asia Top 5\n",
        "    \"XOM\",\"TSM\",\"TCEHY\",\"FXI\",\"EWY\",\n",
        "\n",
        "    # Crypto\n",
        "    \"BTC-USD\",\"ETH-USD\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "API_KEY = \"1VWXIAX2LM6F6WV0\"\n",
        "START_YEAR = 2010\n",
        "TICKERS = [\"AAPL\",\"MSFT\",\"NVDA\",\"SPY\",\"QQQ\",\"VGK\",\"FXI\",\"EWY\",\"XOM\",\"TSM\",\"BTC-USD\",\"ETH-USD\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Alpha Vantage Robust Fetcher Smoke Test ---\n",
            "\n",
            "Testing MSFT...\n",
            "Result: MSFT: rows=100, start=2025-03-27, end=2025-08-19\n",
            "\n",
            "Testing BTC-USD...\n",
            "Result: BTC-USD: rows=350, start=2024-09-05, end=2025-08-20\n",
            "\n",
            "--- Smoke Test Complete ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import json # Ensure json is imported for better error handling/parsing\n",
        "\n",
        "# Updated fetch_alpha_vantage_data_robust function\n",
        "def fetch_alpha_vantage_data_robust(ticker: str, api_key: str, output_size: str = \"full\") -> pd.DataFrame | None:\n",
        "    \"\"\"\n",
        "    Fetch daily OHLCV data from Alpha Vantage for a single ticker (adjusted for stocks).\n",
        "    Handles both TIME_SERIES_DAILY_ADJUSTED for stocks and DIGITAL_CURRENCY_DAILY for crypto.\n",
        "    \"\"\"\n",
        "    base_url = \"https://www.alphavantage.co/query\"\n",
        "    df = None\n",
        "\n",
        "    def print_common_msgs(j: dict, ticker: str) -> bool:\n",
        "        \"\"\"Prints common Alpha Vantage messages (Note, Error Message, etc.) and indicates if it's a failure.\"\"\"\n",
        "        is_failure = False\n",
        "        for k in (\"Note\", \"Error Message\", \"Information\", \"Message\"):\n",
        "            if k in j:\n",
        "                print(f\"{ticker}: {k}: {j[k]}\")\n",
        "                if k in (\"Error Message\", \"Information\", \"Message\") or \"frequency\" in j[k].lower():\n",
        "                    is_failure = True\n",
        "        return is_failure\n",
        "\n",
        "    # Crypto data\n",
        "    if ticker.endswith(\"-USD\"):\n",
        "        params = {\n",
        "            \"function\": \"DIGITAL_CURRENCY_DAILY\",\n",
        "            \"symbol\": ticker.split(\"-\")[0],\n",
        "            \"market\": \"USD\",\n",
        "            \"apikey\": api_key,\n",
        "        }\n",
        "        try:\n",
        "            r = requests.get(base_url, params=params, timeout=20)\n",
        "            r.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "            j = r.json()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request failed for {ticker}: {e}\")\n",
        "            return None\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"{ticker}: Response not JSON: {r.text[:200]}\")\n",
        "            return None\n",
        "\n",
        "        if print_common_msgs(j, ticker):\n",
        "            return None\n",
        "        \n",
        "        key = \"Time Series (Digital Currency Daily)\"\n",
        "        if key not in j:\n",
        "            print(f\"{ticker}: missing '{key}' in response for crypto\")\n",
        "            return None\n",
        "        \n",
        "        ts = j[key]\n",
        "        df = pd.DataFrame.from_dict(ts, orient=\"index\").astype(float)\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        \n",
        "        # *** FIX HERE: Crypto close column is '4. close' based on your diagnostic ***\n",
        "        close_col = \"4. close\"\n",
        "        \n",
        "        if close_col not in df.columns:\n",
        "            print(f\"{ticker}: close column not found in crypto payload. Available: {df.columns.tolist()}\")\n",
        "            return None\n",
        "\n",
        "        df = df.rename(columns={close_col: \"Close\"})\n",
        "        df = df[[\"Close\"]].sort_index()\n",
        "        df[\"Ticker\"] = ticker\n",
        "        return df\n",
        "\n",
        "    # Stock data (adjusted for splits)\n",
        "    params = {\n",
        "        \"function\": \"TIME_SERIES_DAILY_ADJUSTED\",\n",
        "        \"symbol\": ticker,\n",
        "        \"outputsize\": output_size,\n",
        "        \"apikey\": api_key,\n",
        "    }\n",
        "    try:\n",
        "        r = requests.get(base_url, params=params, timeout=20)\n",
        "        r.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        j = r.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed for {ticker}: {e}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"{ticker}: Response not JSON: {r.text[:200]}\")\n",
        "        return None\n",
        "\n",
        "    if print_common_msgs(j, ticker):\n",
        "        return None\n",
        "    \n",
        "    # Accept either \"Time Series (Daily Adjusted)\" or \"Time Series (Daily)\" keys\n",
        "    key = None\n",
        "    if \"Time Series (Daily Adjusted)\" in j:\n",
        "        key = \"Time Series (Daily Adjusted)\"\n",
        "    elif \"Time Series (Daily)\" in j:\n",
        "        key = \"Time Series (Daily)\"\n",
        "    \n",
        "    if key is None:\n",
        "        print(f\"{ticker}: no daily time series key present in response\")\n",
        "        return None\n",
        "    \n",
        "    ts = j[key]\n",
        "    df = pd.DataFrame.from_dict(ts, orient=\"index\").astype(float)\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "    \n",
        "    # Prefer adjusted close when available, else fallback to raw close\n",
        "    close_col = None\n",
        "    if \"5. adjusted close\" in df.columns:\n",
        "        close_col = \"5. adjusted close\"\n",
        "    elif \"4. close\" in df.columns:\n",
        "        close_col = \"4. close\"\n",
        "    \n",
        "    if close_col is None:\n",
        "        print(f\"{ticker}: no close column found (expected '5. adjusted close' or '4. close'). Available: {df.columns.tolist()}\")\n",
        "        return None\n",
        "    \n",
        "    df = df.rename(columns={close_col: \"Close\"})\n",
        "    df = df[[\"Close\"]].sort_index()\n",
        "    df[\"Ticker\"] = ticker\n",
        "    return df\n",
        "\n",
        "# Quick smoke test to verify API key and connectivity\n",
        "print(\"\\n--- Alpha Vantage Robust Fetcher Smoke Test ---\")\n",
        "# Ensure API_KEY is defined in your notebook, e.g., API_KEY = \"YOUR_API_KEY_HERE\"\n",
        "if 'API_KEY' not in globals():\n",
        "    print(\"⚠️ API_KEY not defined. Please define API_KEY = \\\"YOUR_ALPHA_VANTAGE_API_KEY\\\" in a previous cell.\")\n",
        "else:\n",
        "    test_symbols = [\"MSFT\", \"BTC-USD\"]\n",
        "    for sym in test_symbols:\n",
        "        print(f\"\\nTesting {sym}...\")\n",
        "        out = fetch_alpha_vantage_data_robust(sym, API_KEY, output_size=\"compact\") \n",
        "        if out is None:\n",
        "            print(f\"Result: {sym}: fetch failed.\")\n",
        "        else:\n",
        "            print(f\"Result: {sym}: rows={len(out)}, start={out.index.min().date()}, end={out.index.max().date()}\")\n",
        "        time.sleep(12) # Be nice to Alpha Vantage API (5 calls/min limit)\n",
        "print(\"\\n--- Smoke Test Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[STOCK MSFT] GET https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=MSFT&outputsize=compact&apikey=1VWXIAX2LM6F6WV0\n",
            "Status: 200\n",
            "Top-level keys: ['Meta Data', 'Time Series (Daily)']\n",
            "\n",
            "[CRYPTO BTC-USD] GET https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey=1VWXIAX2LM6F6WV0\n",
            "Status: 200\n",
            "Top-level keys: ['Meta Data', 'Time Series (Digital Currency Daily)']\n",
            "Data points: 350; first dates: ['2025-08-20', '2025-08-19', '2025-08-18']\n"
          ]
        }
      ],
      "source": [
        "alpha_vantage_diagnostic(API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching NVDA...\n",
            "⚠️ Failed to fetch NVDA: Unknown error\n",
            "Fetching MSFT...\n",
            "⚠️ Failed to fetch MSFT: Unknown error\n",
            "Fetching AAPL...\n",
            "⚠️ Failed to fetch AAPL: Unknown error\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 85\u001b[39m\n",
            "\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m     84\u001b[39m         all_data.append(df)\n",
            "\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Alpha Vantage rate limit\u001b[39;00m\n",
            "\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_data:\n",
            "\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo data fetched.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# -----------------------------\n",
        "# Portfolio Tickers\n",
        "# -----------------------------\n",
        "TICKERS = [\n",
        "    # Nasdaq Top 20\n",
        "    \"NVDA\",\"MSFT\",\"AAPL\",\"GOOGL\",\"AMZN\",\"META\",\"TSLA\",\"AVGO\",\"TSM\",\"INTC\",\n",
        "    \"ADBE\",\"CMCSA\",\"CSCO\",\"PEP\",\"TXN\",\"PYPL\",\"QCOM\",\"AMGN\",\"GILD\",\"CHTR\",\n",
        "\n",
        "    # Europe Top 10\n",
        "    \"SAP\",\"ASML\",\"MC.PA\",\"RMS.PA\",\"OR.PA\",\"AZN\",\"VGK\",\n",
        "\n",
        "    # Asia Top 5\n",
        "    \"XOM\",\"TSM\",\"TCEHY\",\"FXI\",\"EWY\",\n",
        "\n",
        "    # Crypto\n",
        "    \"BTC-USD\",\"ETH-USD\"\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# Fetching Function\n",
        "# -----------------------------\n",
        "def fetch_alpha_vantage_data(ticker, api_key, output_size='full'):\n",
        "    base_url = \"https://www.alphavantage.co/query\"\n",
        "\n",
        "    if ticker.endswith(\"-USD\"):  # Crypto\n",
        "        params = {\n",
        "            \"function\": \"DIGITAL_CURRENCY_DAILY\",\n",
        "            \"symbol\": ticker.split(\"-\")[0],\n",
        "            \"market\": \"USD\",\n",
        "            \"apikey\": api_key\n",
        "        }\n",
        "    else:  # Stocks\n",
        "        params = {\n",
        "            'function': 'TIME_SERIES_DAILY_ADJUSTED',\n",
        "            'symbol': ticker,\n",
        "            'outputsize': output_size,\n",
        "            'apikey': api_key,\n",
        "            'datatype': 'json'\n",
        "        }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    # Stock data\n",
        "    if \"Time Series (Daily Adjusted)\" in data:\n",
        "        ts = data[\"Time Series (Daily Adjusted)\"]\n",
        "        df = pd.DataFrame.from_dict(ts, orient='index')\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df = df.astype(float)\n",
        "        df = df.rename(columns={'5. adjusted close': 'Close'})\n",
        "        df['Ticker'] = ticker\n",
        "        return df[['Close', 'Ticker']].sort_index()\n",
        "\n",
        "    # Crypto data\n",
        "    elif \"Time Series (Digital Currency Daily)\" in data:\n",
        "        ts = data[\"Time Series (Digital Currency Daily)\"]\n",
        "        df = pd.DataFrame.from_dict(ts, orient='index')\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df = df.astype(float)\n",
        "        df = df.rename(columns={'4a. close (USD)': 'Close'})\n",
        "        df['Ticker'] = ticker\n",
        "        return df[['Close', 'Ticker']].sort_index()\n",
        "\n",
        "    else:\n",
        "        print(f\"⚠️ Failed to fetch {ticker}: {data.get('Note', 'Unknown error')}\")\n",
        "        return None\n",
        "\n",
        "# -----------------------------\n",
        "# Fetch Data\n",
        "# -----------------------------\n",
        "API_KEY = \"1VWXIAX2LM6F6WV0\"\n",
        "all_data = []\n",
        "\n",
        "for ticker in TICKERS:\n",
        "    print(f\"Fetching {ticker}...\")\n",
        "    df = fetch_alpha_vantage_data(ticker, API_KEY)\n",
        "    if df is not None:\n",
        "        all_data.append(df)\n",
        "    time.sleep(12)  # Alpha Vantage rate limit\n",
        "\n",
        "if not all_data:\n",
        "    raise RuntimeError(\"No data fetched.\")\n",
        "\n",
        "data = pd.concat(all_data)\n",
        "\n",
        "# -----------------------------\n",
        "# Plot Adjusted Close Prices\n",
        "# -----------------------------\n",
        "tickers = data['Ticker'].unique()\n",
        "fig, axes = plt.subplots(len(tickers), 1, figsize=(14, 2*len(tickers)))\n",
        "fig.suptitle('Adjusted Close Prices', fontsize=16, y=0.98)\n",
        "\n",
        "if len(tickers) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, ticker in enumerate(tickers):\n",
        "    ax = axes[i]\n",
        "    ticker_data = data[data['Ticker'] == ticker]\n",
        "\n",
        "    if not ticker_data.index.is_unique:\n",
        "        ticker_data = ticker_data.groupby(ticker_data.index).mean(numeric_only=True)\n",
        "\n",
        "    ax.plot(ticker_data.index, ticker_data['Close'], label=ticker, linewidth=1.5)\n",
        "    ax.set_title(ticker)\n",
        "    ax.set_ylabel('Price')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    ax.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching NVDA...\n",
            "⚠️ Failed to fetch NVDA: Unknown error\n",
            "Fetching MSFT...\n",
            "⚠️ Failed to fetch MSFT: Unknown error\n",
            "Fetching AAPL...\n",
            "⚠️ Failed to fetch AAPL: Unknown error\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 85\u001b[39m\n",
            "\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m     84\u001b[39m         all_data.append(df)\n",
            "\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Alpha Vantage rate limit\u001b[39;00m\n",
            "\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_data:\n",
            "\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo data fetched.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# -----------------------------\n",
        "# Portfolio Tickers\n",
        "# -----------------------------\n",
        "TICKERS = [\n",
        "    # Nasdaq Top 20\n",
        "    \"NVDA\",\"MSFT\",\"AAPL\",\"GOOGL\",\"AMZN\",\"META\",\"TSLA\",\"AVGO\",\"TSM\",\"INTC\",\n",
        "    \"ADBE\",\"CMCSA\",\"CSCO\",\"PEP\",\"TXN\",\"PYPL\",\"QCOM\",\"AMGN\",\"GILD\",\"CHTR\",\n",
        "\n",
        "    # Europe Top 10\n",
        "    \"SAP\",\"ASML\",\"MC.PA\",\"RMS.PA\",\"OR.PA\",\"AZN\",\"VGK\",\n",
        "\n",
        "    # Asia Top 5\n",
        "    \"XOM\",\"TSM\",\"TCEHY\",\"FXI\",\"EWY\",\n",
        "\n",
        "    # Crypto\n",
        "    \"BTC-USD\",\"ETH-USD\"\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# Fetching Function\n",
        "# -----------------------------\n",
        "def fetch_alpha_vantage_data(ticker, api_key, output_size='full'):\n",
        "    base_url = \"https://www.alphavantage.co/query\"\n",
        "\n",
        "    if ticker.endswith(\"-USD\"):  # Crypto\n",
        "        params = {\n",
        "            \"function\": \"DIGITAL_CURRENCY_DAILY\",\n",
        "            \"symbol\": ticker.split(\"-\")[0],\n",
        "            \"market\": \"USD\",\n",
        "            \"apikey\": api_key\n",
        "        }\n",
        "    else:  # Stocks\n",
        "        params = {\n",
        "            'function': 'TIME_SERIES_DAILY_ADJUSTED',\n",
        "            'symbol': ticker,\n",
        "            'outputsize': output_size,\n",
        "            'apikey': api_key,\n",
        "            'datatype': 'json'\n",
        "        }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    # Stock data\n",
        "    if \"Time Series (Daily Adjusted)\" in data:\n",
        "        ts = data[\"Time Series (Daily Adjusted)\"]\n",
        "        df = pd.DataFrame.from_dict(ts, orient='index')\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df = df.astype(float)\n",
        "        df = df.rename(columns={'5. adjusted close': 'Close'})\n",
        "        df['Ticker'] = ticker\n",
        "        return df[['Close', 'Ticker']].sort_index()\n",
        "\n",
        "    # Crypto data\n",
        "    elif \"Time Series (Digital Currency Daily)\" in data:\n",
        "        ts = data[\"Time Series (Digital Currency Daily)\"]\n",
        "        df = pd.DataFrame.from_dict(ts, orient='index')\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df = df.astype(float)\n",
        "        df = df.rename(columns={'4a. close (USD)': 'Close'})\n",
        "        df['Ticker'] = ticker\n",
        "        return df[['Close', 'Ticker']].sort_index()\n",
        "\n",
        "    else:\n",
        "        print(f\"⚠️ Failed to fetch {ticker}: {data.get('Note', 'Unknown error')}\")\n",
        "        return None\n",
        "\n",
        "# -----------------------------\n",
        "# Fetch Data\n",
        "# -----------------------------\n",
        "API_KEY = \"1VWXIAX2LM6F6WV0\"\n",
        "all_data = []\n",
        "\n",
        "for ticker in TICKERS:\n",
        "    print(f\"Fetching {ticker}...\")\n",
        "    df = fetch_alpha_vantage_data(ticker, API_KEY)\n",
        "    if df is not None:\n",
        "        all_data.append(df)\n",
        "    time.sleep(12)  # Alpha Vantage rate limit\n",
        "\n",
        "if not all_data:\n",
        "    raise RuntimeError(\"No data fetched.\")\n",
        "\n",
        "data = pd.concat(all_data)\n",
        "\n",
        "# -----------------------------\n",
        "# Plot Adjusted Close Prices\n",
        "# -----------------------------\n",
        "tickers = data['Ticker'].unique()\n",
        "fig, axes = plt.subplots(len(tickers), 1, figsize=(14, 2*len(tickers)))\n",
        "fig.suptitle('Adjusted Close Prices', fontsize=16, y=0.98)\n",
        "\n",
        "if len(tickers) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, ticker in enumerate(tickers):\n",
        "    ax = axes[i]\n",
        "    ticker_data = data[data['Ticker'] == ticker]\n",
        "\n",
        "    if not ticker_data.index.is_unique:\n",
        "        ticker_data = ticker_data.groupby(ticker_data.index).mean(numeric_only=True)\n",
        "\n",
        "    ax.plot(ticker_data.index, ticker_data['Close'], label=ticker, linewidth=1.5)\n",
        "    ax.set_title(ticker)\n",
        "    ax.set_ylabel('Price')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    ax.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching NVDA...\n",
            "⚠️ Failed to fetch NVDA: Unknown error\n",
            "Fetching MSFT...\n",
            "⚠️ Failed to fetch MSFT: Unknown error\n",
            "Fetching AAPL...\n",
            "⚠️ Failed to fetch AAPL: Unknown error\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     84\u001b[39m         all_data.append(df)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Alpha Vantage rate limit\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_data:\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo data fetched.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# -----------------------------\n",
        "# Portfolio Tickers\n",
        "# -----------------------------\n",
        "TICKERS = [\n",
        "    # Nasdaq Top 20\n",
        "    \"NVDA\",\"MSFT\",\"AAPL\",\"GOOGL\",\"AMZN\",\"META\",\"TSLA\",\"AVGO\",\"TSM\",\"INTC\",\n",
        "    \"ADBE\",\"CMCSA\",\"CSCO\",\"PEP\",\"TXN\",\"PYPL\",\"QCOM\",\"AMGN\",\"GILD\",\"CHTR\",\n",
        "\n",
        "    # Europe Top 10\n",
        "    \"SAP\",\"ASML\",\"MC.PA\",\"RMS.PA\",\"OR.PA\",\"AZN\",\"VGK\",\n",
        "\n",
        "    # Asia Top 5\n",
        "    \"XOM\",\"TSM\",\"TCEHY\",\"FXI\",\"EWY\",\n",
        "\n",
        "    # Crypto\n",
        "    \"BTC-USD\",\"ETH-USD\"\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# Fetching Function\n",
        "# -----------------------------\n",
        "def fetch_alpha_vantage_data(ticker, api_key, output_size='full'):\n",
        "    base_url = \"https://www.alphavantage.co/query\"\n",
        "\n",
        "    if ticker.endswith(\"-USD\"):  # Crypto\n",
        "        params = {\n",
        "            \"function\": \"DIGITAL_CURRENCY_DAILY\",\n",
        "            \"symbol\": ticker.split(\"-\")[0],\n",
        "            \"market\": \"USD\",\n",
        "            \"apikey\": api_key\n",
        "        }\n",
        "    else:  # Stocks\n",
        "        params = {\n",
        "            'function': 'TIME_SERIES_DAILY_ADJUSTED',\n",
        "            'symbol': ticker,\n",
        "            'outputsize': output_size,\n",
        "            'apikey': api_key,\n",
        "            'datatype': 'json'\n",
        "        }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    # Stock data\n",
        "    if \"Time Series (Daily Adjusted)\" in data:\n",
        "        ts = data[\"Time Series (Daily Adjusted)\"]\n",
        "        df = pd.DataFrame.from_dict(ts, orient='index')\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df = df.astype(float)\n",
        "        df = df.rename(columns={'5. adjusted close': 'Close'})\n",
        "        df['Ticker'] = ticker\n",
        "        return df[['Close', 'Ticker']].sort_index()\n",
        "\n",
        "    # Crypto data\n",
        "    elif \"Time Series (Digital Currency Daily)\" in data:\n",
        "        ts = data[\"Time Series (Digital Currency Daily)\"]\n",
        "        df = pd.DataFrame.from_dict(ts, orient='index')\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df = df.astype(float)\n",
        "        df = df.rename(columns={'4a. close (USD)': 'Close'})\n",
        "        df['Ticker'] = ticker\n",
        "        return df[['Close', 'Ticker']].sort_index()\n",
        "\n",
        "    else:\n",
        "        print(f\"⚠️ Failed to fetch {ticker}: {data.get('Note', 'Unknown error')}\")\n",
        "        return None\n",
        "\n",
        "# -----------------------------\n",
        "# Fetch Data\n",
        "# -----------------------------\n",
        "API_KEY = \"1VWXIAX2LM6F6WV0\"\n",
        "all_data = []\n",
        "\n",
        "for ticker in TICKERS:\n",
        "    print(f\"Fetching {ticker}...\")\n",
        "    df = fetch_alpha_vantage_data(ticker, API_KEY)\n",
        "    if df is not None:\n",
        "        all_data.append(df)\n",
        "    time.sleep(12)  # Alpha Vantage rate limit\n",
        "\n",
        "if not all_data:\n",
        "    raise RuntimeError(\"No data fetched.\")\n",
        "\n",
        "data = pd.concat(all_data)\n",
        "\n",
        "# -----------------------------\n",
        "# Plot Adjusted Close Prices\n",
        "# -----------------------------\n",
        "tickers = data['Ticker'].unique()\n",
        "fig, axes = plt.subplots(len(tickers), 1, figsize=(14, 2*len(tickers)))\n",
        "fig.suptitle('Adjusted Close Prices', fontsize=16, y=0.98)\n",
        "\n",
        "if len(tickers) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, ticker in enumerate(tickers):\n",
        "    ax = axes[i]\n",
        "    ticker_data = data[data['Ticker'] == ticker]\n",
        "\n",
        "    if not ticker_data.index.is_unique:\n",
        "        ticker_data = ticker_data.groupby(ticker_data.index).mean(numeric_only=True)\n",
        "\n",
        "    ax.plot(ticker_data.index, ticker_data['Close'], label=ticker, linewidth=1.5)\n",
        "    ax.set_title(ticker)\n",
        "    ax.set_ylabel('Price')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    ax.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'AssetClass'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/NEL_Lab/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'AssetClass'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmdates\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Get unique asset classes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m asset_classes = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAssetClass\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.unique()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Create subplots\u001b[39;00m\n\u001b[32m      8\u001b[39m fig, axes = plt.subplots(\u001b[38;5;28mlen\u001b[39m(asset_classes), \u001b[32m1\u001b[39m, figsize=(\u001b[32m14\u001b[39m, \u001b[32m3\u001b[39m*\u001b[38;5;28mlen\u001b[39m(asset_classes)))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/NEL_Lab/venv/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/NEL_Lab/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'AssetClass'"
          ]
        }
      ],
      "source": [
        "# Get unique asset classes\n",
        "asset_classes = data['AssetClass'].unique()\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(len(asset_classes), 1, figsize=(14, 3*len(asset_classes)))\n",
        "fig.suptitle('Asset Class Performance', fontsize=16, y=0.98)\n",
        "\n",
        "for i, asset in enumerate(asset_classes):\n",
        "    ax = axes[i]\n",
        "    asset_data = data[data['AssetClass'] == asset]\n",
        "    \n",
        "    # Plot closing price\n",
        "    ax.plot(asset_data.index.get_level_values('Date'), \n",
        "            asset_data['Close'], \n",
        "            label=f'{asset} Close', \n",
        "            linewidth=1.5)\n",
        "    \n",
        "    # Formatting\n",
        "    ax.set_title(asset)\n",
        "    ax.set_ylabel('Price')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    \n",
        "    # Add legend\n",
        "    ax.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust for suptitle\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Indicator:\n",
        "    def __init__(self, data: pd.DataFrame):\n",
        "        \"\"\"\n",
        "        Comprehensive technical indicator suite\n",
        "        :param data: DataFrame with OHLCV columns and datetime index\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "    \n",
        "    def rsi(self, period: int = 14) -> pd.Series:\n",
        "        \"\"\"Calculate the Relative Strength Index (RSI) with Wilder's smoothing.\"\"\"\n",
        "        delta = self.data['Close'].diff()\n",
        "        gain = delta.where(delta > 0, 0)\n",
        "        loss = -delta.where(delta < 0, 0)\n",
        "        \n",
        "        avg_gain = gain.ewm(alpha=1/period, adjust=False).mean()\n",
        "        avg_loss = loss.ewm(alpha=1/period, adjust=False).mean()\n",
        "        \n",
        "        rs = avg_gain / avg_loss\n",
        "        rs = rs.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "        return 100 - (100 / (1 + rs))\n",
        "    \n",
        "    def adx(self, period: int = 14) -> pd.Series:\n",
        "        \"\"\"Calculate the Average Directional Index (ADX) for trend strength.\"\"\"\n",
        "        high, low, close = self.data['High'], self.data['Low'], self.data['Close']\n",
        "        \n",
        "        # Calculate directional movements\n",
        "        up_move = high.diff()\n",
        "        down_move = low.diff().abs()\n",
        "        plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0.0)\n",
        "        minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)\n",
        "        \n",
        "        # Calculate true range\n",
        "        tr = pd.concat([\n",
        "            high - low,\n",
        "            (high - close.shift(1)).abs(),\n",
        "            (low - close.shift(1)).abs()\n",
        "        ], axis=1).max(axis=1)\n",
        "        \n",
        "        # Smooth values\n",
        "        alpha = 1 / period\n",
        "        atr = tr.ewm(alpha=alpha, adjust=False).mean()\n",
        "        plus_di = 100 * plus_dm.ewm(alpha=alpha, adjust=False).mean() / atr\n",
        "        minus_di = 100 * minus_dm.ewm(alpha=alpha, adjust=False).mean() / atr\n",
        "        \n",
        "        # Calculate DX and ADX\n",
        "        dx = 100 * np.abs(plus_di - minus_di) / (plus_di + minus_di)\n",
        "        return dx.ewm(alpha=alpha, adjust=False).mean()\n",
        "    \n",
        "    def kama(self, fast_period: int = 7, slow_period: int = 19, \n",
        "             er_period: int = 8, norm_period: int = 50, \n",
        "             normalize: bool = True) -> pd.Series:\n",
        "        \"\"\"\n",
        "        Calculate Kaufman Adaptive Moving Average (KAMA) with normalization.\n",
        "        :param fast_period: Fast EMA period (default 7)\n",
        "        :param slow_period: Slow EMA period (default 19)\n",
        "        :param er_period: Efficiency ratio period (default 8)\n",
        "        :param norm_period: Normalization lookback (default 50)\n",
        "        :param normalize: Whether to normalize the oscillator (default True)\n",
        "        :return: Normalized KAMA oscillator series\n",
        "        \"\"\"\n",
        "        close = self.data['Close']\n",
        "        \n",
        "        # Calculate efficiency ratio\n",
        "        change = (close - close.shift(er_period)).abs()\n",
        "        volatility = close.diff().abs().rolling(window=er_period).sum()\n",
        "        er = change / volatility\n",
        "        er = er.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "        \n",
        "        # Calculate smoothing constant\n",
        "        sc = er * (2/(fast_period + 1) - 2/(slow_period + 1)) + 2/(slow_period + 1)\n",
        "        \n",
        "        # Calculate KAMA\n",
        "        kama = pd.Series(np.nan, index=close.index)\n",
        "        kama.iloc[0] = close.iloc[0]\n",
        "        \n",
        "        for i in range(1, len(close)):\n",
        "            kama.iloc[i] = kama.iloc[i-1] + sc.iloc[i] * (close.iloc[i] - kama.iloc[i-1])\n",
        "        \n",
        "        if not normalize:\n",
        "            return kama\n",
        "        \n",
        "        # Normalize the oscillator\n",
        "        lowest = kama.rolling(window=norm_period).min()\n",
        "        highest = kama.rolling(window=norm_period).max()\n",
        "        range_val = highest - lowest\n",
        "        normalized = (kama - lowest) / range_val - 0.5\n",
        "        normalized = normalized.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "        \n",
        "        return normalized\n",
        "    \n",
        "    def atr(self, period: int = 14) -> pd.Series:\n",
        "        \"\"\"\n",
        "        Calculate Average True Range (ATR) for volatility measurement.\n",
        "        :param period: Lookback period for ATR calculation\n",
        "        :return: Series of ATR values\n",
        "        \"\"\"\n",
        "        high, low, close = self.data['High'], self.data['Low'], self.data['Close']\n",
        "        \n",
        "        # Calculate true range\n",
        "        tr1 = high - low\n",
        "        tr2 = (high - close.shift(1)).abs()\n",
        "        tr3 = (low - close.shift(1)).abs()\n",
        "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "        \n",
        "        # Calculate ATR with Wilder's smoothing\n",
        "        return tr.ewm(alpha=1/period, adjust=False).mean()\n",
        "    \n",
        "    def mfi(self, period: int = 14) -> pd.Series:\n",
        "        \"\"\"\n",
        "        Calculate Money Flow Index (MFI) for volume-based momentum.\n",
        "        :param period: Lookback period for MFI calculation\n",
        "        :return: Series of MFI values (0-100)\n",
        "        \"\"\"\n",
        "        high, low, close, volume = self.data['High'], self.data['Low'], self.data['Close'], self.data['Volume']\n",
        "        \n",
        "        # Calculate typical price\n",
        "        typical_price = (high + low + close) / 3\n",
        "        \n",
        "        # Calculate raw money flow\n",
        "        money_flow = typical_price * volume\n",
        "        \n",
        "        # Determine positive/negative money flow\n",
        "        price_diff = typical_price.diff()\n",
        "        positive_flow = np.where(price_diff > 0, money_flow, 0)\n",
        "        negative_flow = np.where(price_diff < 0, money_flow, 0)\n",
        "        \n",
        "        # Calculate money flow ratio\n",
        "        pos_flow_sum = pd.Series(positive_flow).rolling(window=period).sum()\n",
        "        neg_flow_sum = pd.Series(negative_flow).rolling(window=period).sum()\n",
        "        money_ratio = pos_flow_sum / neg_flow_sum\n",
        "        \n",
        "        # Calculate MFI\n",
        "        mfi = 100 - (100 / (1 + money_ratio))\n",
        "        return mfi.replace([np.inf, -np.inf], np.nan).fillna(50)  # 50 is neutral\n",
        "    \n",
        "    def entropy(self, window: int = 10, bins: int = 5) -> pd.Series:\n",
        "        \"\"\"Calculate Shannon's Entropy of returns distribution.\"\"\"\n",
        "        returns = self.data['Close'].pct_change().dropna()\n",
        "        entropy_vals = pd.Series(np.nan, index=self.data.index)\n",
        "        \n",
        "        for i in range(window, len(returns)):\n",
        "            window_returns = returns.iloc[i-window:i]\n",
        "            hist, _ = np.histogram(window_returns, bins=bins)\n",
        "            prob = hist / hist.sum()\n",
        "            entropy_vals.iloc[i] = entropy(prob)\n",
        "        \n",
        "        return entropy_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# buying and selling logic of indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# individueel plotten met buy strats gewoon voor visual en check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2018 tot 2022 modelleren wellicht en out of sample er voor of er na chechken,\n",
        "\n",
        "# rollen sharpe en marco lopez sharpe checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Robust Alpha Vantage fetcher (handles both Daily and Daily Adjusted keys)\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "\n",
        "def fetch_alpha_vantage_data_robust(ticker: str, api_key: str, output_size: str = \"full\") -> pd.DataFrame | None:\n",
        "    base_url = \"https://www.alphavantage.co/query\"\n",
        "\n",
        "    def print_common_msgs(j: dict, ticker: str) -> bool:\n",
        "        for k in (\"Note\", \"Error Message\", \"Information\", \"Message\"):\n",
        "            if k in j:\n",
        "                print(f\"{ticker}: {k}: {j[k]}\")\n",
        "                # Return True if this likely indicates a failure\n",
        "                if k in (\"Error Message\", \"Information\", \"Message\") or \"frequency\" in j[k].lower():\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    # Crypto\n",
        "    if ticker.endswith(\"-USD\"):\n",
        "        params = {\n",
        "            \"function\": \"DIGITAL_CURRENCY_DAILY\",\n",
        "            \"symbol\": ticker.split(\"-\")[0],\n",
        "            \"market\": \"USD\",\n",
        "            \"apikey\": api_key,\n",
        "        }\n",
        "        r = requests.get(base_url, params=params, timeout=20)\n",
        "        j = r.json()\n",
        "        if print_common_msgs(j, ticker):\n",
        "            return None\n",
        "        key = \"Time Series (Digital Currency Daily)\"\n",
        "        if key not in j:\n",
        "            print(f\"{ticker}: missing '{key}' in response\")\n",
        "            return None\n",
        "        ts = j[key]\n",
        "        df = pd.DataFrame.from_dict(ts, orient=\"index\").astype(float)\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        close_col = \"4a. close (USD)\" if \"4a. close (USD)\" in df.columns else \"4b. close (USD)\"\n",
        "        if close_col not in df.columns:\n",
        "            print(f\"{ticker}: close column not found in crypto payload\")\n",
        "            return None\n",
        "        df = df.rename(columns={close_col: \"Close\"})\n",
        "        df = df[[\"Close\"]].sort_index()\n",
        "        df[\"Ticker\"] = ticker\n",
        "        return df\n",
        "\n",
        "    # Stocks\n",
        "    params = {\n",
        "        \"function\": \"TIME_SERIES_DAILY_ADJUSTED\",\n",
        "        \"symbol\": ticker,\n",
        "        \"outputsize\": output_size,\n",
        "        \"apikey\": api_key,\n",
        "    }\n",
        "    r = requests.get(base_url, params=params, timeout=20)\n",
        "    j = r.json()\n",
        "    if print_common_msgs(j, ticker):\n",
        "        # If rate-limited, caller can sleep and retry\n",
        "        pass\n",
        "    # Accept either key name\n",
        "    key = \"Time Series (Daily Adjusted)\" if \"Time Series (Daily Adjusted)\" in j else \"Time Series (Daily)\" if \"Time Series (Daily)\" in j else None\n",
        "    if key is None:\n",
        "        print(f\"{ticker}: no daily time series key present\")\n",
        "        return None\n",
        "    ts = j[key]\n",
        "    df = pd.DataFrame.from_dict(ts, orient=\"index\").astype(float)\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "    # Prefer adjusted close when available, else fallback to raw close\n",
        "    close_col = \"5. adjusted close\" if \"5. adjusted close\" in df.columns else (\"4. close\" if \"4. close\" in df.columns else None)\n",
        "    if close_col is None:\n",
        "        print(f\"{ticker}: no close column found (expected '5. adjusted close' or '4. close')\")\n",
        "        return None\n",
        "    df = df.rename(columns={close_col: \"Close\"})\n",
        "    df = df[[\"Close\"]].sort_index()\n",
        "    df[\"Ticker\"] = ticker\n",
        "    return df\n",
        "\n",
        "# Quick smoke test\n",
        "print(\"\\nRobust fetcher smoke test (MSFT, BTC-USD):\")\n",
        "for sym in [\"MSFT\", \"BTC-USD\"]:\n",
        "    out = fetch_alpha_vantage_data_robust(sym, API_KEY, output_size=\"compact\") if 'API_KEY' in globals() else None\n",
        "    if out is None:\n",
        "        print(f\"{sym}: fetch failed\")\n",
        "    else:\n",
        "        print(f\"{sym}: rows={len(out)}, start={out.index.min().date()}, end={out.index.max().date()}\")\n",
        "        # Be nice to API\n",
        "        time.sleep(12)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alpha Vantage API diagnostics\n",
        "import requests, json\n",
        "\n",
        "def alpha_vantage_diagnostic(api_key: str, stock_symbol: str = \"MSFT\", crypto_symbol: str = \"BTC\") -> None:\n",
        "    \"\"\"\n",
        "    Make simple test calls to Alpha Vantage and print rich diagnostics so you can see\n",
        "    whether the API is reachable, if you're rate-limited, or if the key is invalid.\n",
        "    \"\"\"\n",
        "    base_url = \"https://www.alphavantage.co/query\"\n",
        "\n",
        "    def do_call(params: dict, label: str) -> None:\n",
        "        try:\n",
        "            r = requests.get(base_url, params=params, timeout=20)\n",
        "            print(f\"\\n[{label}] GET {r.url}\")\n",
        "            print(f\"Status: {r.status_code}\")\n",
        "            try:\n",
        "                j = r.json()\n",
        "            except ValueError:\n",
        "                print(\"Response not JSON. First 200 chars:\")\n",
        "                print(r.text[:200])\n",
        "                return\n",
        "            # Top-level keys present in the response\n",
        "            print(\"Top-level keys:\", list(j.keys()))\n",
        "            # Common informational/error fields Alpha Vantage returns\n",
        "            for k in (\"Note\", \"Error Message\", \"Information\", \"Message\"):\n",
        "                if k in j:\n",
        "                    print(f\"{k}: {j[k]}\")\n",
        "            # If data is present, show a tiny sample\n",
        "            for k in (\"Time Series (Daily Adjusted)\", \"Time Series (Digital Currency Daily)\"):\n",
        "                if k in j:\n",
        "                    ts = j[k]\n",
        "                    keys = list(ts.keys())\n",
        "                    print(f\"Data points: {len(keys)}; first dates: {keys[:3]}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Request failed: {e}\")\n",
        "\n",
        "    # Test a stock endpoint\n",
        "    do_call(\n",
        "        {\n",
        "            \"function\": \"TIME_SERIES_DAILY_ADJUSTED\",\n",
        "            \"symbol\": stock_symbol,\n",
        "            \"outputsize\": \"compact\",\n",
        "            \"apikey\": api_key,\n",
        "        },\n",
        "        f\"STOCK {stock_symbol}\",\n",
        "    )\n",
        "\n",
        "    # Test a crypto endpoint\n",
        "    do_call(\n",
        "        {\n",
        "            \"function\": \"DIGITAL_CURRENCY_DAILY\",\n",
        "            \"symbol\": crypto_symbol,\n",
        "            \"market\": \"USD\",\n",
        "            \"apikey\": api_key,\n",
        "        },\n",
        "        f\"CRYPTO {crypto_symbol}-USD\",\n",
        "    )\n",
        "\n",
        "print(\"Run alpha_vantage_diagnostic(API_KEY) to test connectivity and rate limits.\")\n",
        "# Example:\n",
        "# alpha_vantage_diagnostic(API_KEY)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (venv)",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
